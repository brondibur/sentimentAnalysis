{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python_defaultSpec_1598546220412",
   "display_name": "Python 3.8.3 64-bit"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Datasets:\n",
    "\n",
    "    https://www.kaggle.com/utathya/imdb-review-dataset\n",
    "    http://ai.stanford.edu/~amaas/data/sentiment/ (better)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "# Reading the csv dataset into a pandas dataframe\n",
    "df = pd.read_csv('E:/Internships/TCS-iON/Code/MyCode/IMDB/imdb_master.csv', encoding = 'ISO-8859-1') \n",
    "# Adding a column representing 1 for 'pos' and 0 for 'neg' sentiments\n",
    "df['senti'] = df.apply(lambda x: 1 if x['label'] == 'pos' else 0, axis = 1) \n",
    "# Deleting unnecessary columns\n",
    "df = df.drop(['Unnamed: 0', 'type', 'file'], axis = 1) \n",
    "# Converting the data type to string \n",
    "df['review'] = df[\"review\"].astype(\"str\")\n",
    "# Converting all text to lowercase for use\n",
    "df['review'] = df['review'].str.lower()\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<table border = '1'>\n",
    "<tr align = 'center'>\n",
    "<td>review</td><td></td>\t<td>label</td><td></td>\t<td>senti</td>\n",
    "<hr>\n",
    "</tr>\n",
    "<tr>\n",
    "<td>once again mr. costner has dragged out a movie...</td><td></td>\t<td>neg</td><td></td>\t<td>0</td>\n",
    "</tr>\n",
    "<tr>\n",
    "<td>this is an example of why the majority of acti...</td><td></td>\t<td>neg</td><td></td>\t<td>0</td>\n",
    "</tr>\n",
    "<tr>\n",
    "<td>first of all i hate those moronic rappers, who...</td><td></td>\t<td>neg</td><td></td>\t<td>0</td>\n",
    "</tr>\n",
    "<tr>\n",
    "<td>not even the beatles could write songs everyon...</td><td></td>\t<td>neg</td><td></td>\t<td>0</td>\n",
    "</tr>\n",
    "<tr>\n",
    "<td>brass pictures (movies is not a fitting word f...</td><td></td>\t<td>neg</td><td></td>\t<td>0</td>\n",
    "</tr>\n",
    "</table>    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "once again mr. costner has dragged out a movie for far longer than necessary. aside from the terrific sea rescue sequences, of which there are very few i just did not care about any of the characters. most of us have ghosts in the closet, and costner's character are realized early on, and then forgotten until much later, by which time i did not care. the character we should really care about is a very cocky, overconfident ashton kutcher. the problem is he comes off as kid who thinks he's better than anyone else around him and shows no signs of a cluttered closet. his only obstacle appears to be winning over costner. finally when we are well past the half way point of this stinker, costner tells us all about kutcher's ghosts. we are told why kutcher is driven to be the best with no prior inkling or foreshadowing. no magic here, it was all i could do to keep from turning it off an hour in."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import re\n",
    "import string\n",
    "from nltk import WordNetLemmatizer\n",
    "from nltk.stem.snowball import SnowballStemmer\n",
    "from nltk.corpus import stopwords\n",
    "# Initialising the nltk stop_words, stemmer and lemmatizer functions\n",
    "stop_words = set(stopwords.words(\"english\")) \n",
    "lemmatizer = WordNetLemmatizer()\n",
    "stemmer = SnowballStemmer(\"english\")\n",
    "# Creating a function for text cleaning\n",
    "def textCleanser(myText):\n",
    "    # Removing the name titles and the period symbols after it\n",
    "    myText = re.sub(r'[mdsr]r(s)?\\.', '', myText)\n",
    "    # Removing punctuation\n",
    "    myPunct = string.punctuation\n",
    "    punctToSpace = str.maketrans(myPunct, len(myPunct)*' ')   \n",
    "    myText = myText.translate(punctToSpace) \n",
    "    # Removing the '@username' mentions\n",
    "    myText = re.sub(r'@\\w+', '', myText)\n",
    "    # Removing urls\n",
    "    myText = re.sub(r'(http(s)?://)?(www\\.)?.+\\.com', '', myText)\n",
    "    # Removing numbers\n",
    "    myText = re.sub(r'\\d+', '', myText)    \n",
    "    # Removing stopwords\n",
    "    myText = [word for word in myText.split(' ') if not word in stop_words]\n",
    "    myText = [word for word in myText if word != '']\n",
    "    # Lemmatizing the text\n",
    "    myText = [lemmatizer.lemmatize(token) for token in myText]\n",
    "    # Stemming the text\n",
    "    # myText = [stemmer.stem(token) for token in myText]\n",
    "    return myText\n",
    "for i in range(len(df['review'])):\n",
    "    df['review'][i] = textCleanser(df['review'][i])\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<table border = '1'>\n",
    "<tr align = 'center'>\n",
    "<td>review</td><td></td>\t<td>label</td><td></td>\t<td>senti</td>\n",
    "<hr>\n",
    "</tr>\n",
    "<tr>\n",
    "<td>[costner, dragged, movie, far, longer, necessa...</td><td></td>\t<td>neg</td><td></td>\t<td>0</td>\n",
    "</tr>\n",
    "<tr>\n",
    "<td>[example, majority, action, film, generic, bor...</td><td></td>\t<td>neg</td><td></td>\t<td>0</td>\n",
    "</tr>\n",
    "<tr>\n",
    "<td>[first, hate, moronic, rapper, could, nt, act,...</td><td></td>\t<td>neg</td><td></td>\t<td>0</td>\n",
    "</tr>\n",
    "<tr>\n",
    "<td>[even, beatles, could, write, song, everyone, ...</td><td></td>\t<td>neg</td><td></td>\t<td>0</td>\n",
    "</tr>\n",
    "<tr>\n",
    "<td>[brass, picture, movie, fitting, word, really,...</td><td></td>\t<td>neg</td><td></td>\t<td>0</td>\n",
    "</tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "['costner', 'dragged', 'movie', 'far', 'longer', 'necessary', 'aside', 'terrific', 'sea', 'rescue', 'sequence', 'care', 'character', 'u', 'ghost', 'closet', 'costner', 'character', 'realized', 'early', 'forgotten', 'much', 'later', 'time', 'care', 'character', 'really', 'care', 'cocky', 'overconfident', 'ashton', 'kutcher', 'problem', 'come', 'kid', 'think', 'better', 'anyone', 'else', 'around', 'show', 'sign', 'cluttered', 'closet', 'obstacle', 'appears', 'winning', 'costner', 'finally', 'well', 'past', 'half', 'way', 'point', 'stinker', 'costner', 'tell', 'u', 'kutcher', 'ghost', 'told', 'kutcher', 'driven', 'best', 'prior', 'inkling', 'foreshadowing', 'magic', 'could', 'keep', 'turning', 'hour']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "myReviews = []\n",
    "for i in range(len(df['review'])):\n",
    "    for j in df['review'][i]:\n",
    "        if j != 'br':\n",
    "            myReviews.append(j)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "import collections\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.model_selection import GridSearchCV, train_test_split\n",
    "from sklearn.pipeline import Pipeline, FeatureUnion\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import numpy as np \n",
    "np.random.seed(1234)\n",
    "# Initialising the Count Vectorizer\n",
    "cv = CountVectorizer()\n",
    "myBow = cv.fit_transform(myReviews)\n",
    "wordFrequency = dict(zip(cv.get_feature_names(), np.asarray(myBow.sum(axis = 0)).ravel()))\n",
    "wordCounter = collections.Counter(wordFrequency)\n",
    "# Storing the frequency of appearance of words\n",
    "dfWordCounter = pd.DataFrame(wordCounter.most_common(25), columns = ['word', 'frequency'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting the top 25 most frequently occuring words\n",
    "plt.close('all')\n",
    "fig, ax = plt.subplots(figsize = (17, 15))\n",
    "sns.barplot(x = 'word', y = 'frequency', data = dfWordCounter, ax = ax)\n",
    "sns.set_palette('pastel') \n",
    "plt.xlabel('Words')\n",
    "plt.ylabel('Frequency of appearance of words')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"top25words.png\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "import random\n",
    "import torch\n",
    "import torchtext\n",
    "from torchtext import data\n",
    "import spacy\n",
    "import en_core_web_sm\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as fn\n",
    "SEED = 1234\n",
    "random.seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "torch.manual_seed(SEED)\n",
    "torch.backends.cudnn.deterministic = True\n",
    "# Creating Field objects and setting batch_first to true so that we can input the batches to the cnn\n",
    "TEXT = data.Field(tokenize = 'spacy', batch_first = True)\n",
    "LABEL = data.LabelField(dtype = torch.float)\n",
    "# Creating training and testing datasets\n",
    "training, testing = train_test_split(df, test_size=0.2, random_state=42)\n",
    "training, validating = train_test_split(training, test_size=0.2, random_state=42)\n",
    "training.to_csv('training.csv')\n",
    "validating.to_csv('validating.csv')\n",
    "testing.to_csv('testing.csv')\n",
    "fields = [(None, None), ('c', TEXT), (None, None), ('s', LABEL)]\n",
    "train_data, valid_data, test_data = data.TabularDataset.splits(\n",
    "    path = 'E:/Internships/TCS-iON/Code/MyCode/IMDB/',\n",
    "    train = 'training.csv',\n",
    "    validation = 'validating.csv',\n",
    "    test = 'testing.csv',\n",
    "    format = 'csv',\n",
    "    fields = fields,\n",
    "    skip_header = True\n",
    ")\n",
    "MAX_VOCAB_SIZE = 50000\n",
    "# Building the vocabularies\n",
    "TEXT.build_vocab(\n",
    "    train_data, \n",
    "    max_size = MAX_VOCAB_SIZE, \n",
    "    # Using the glove.6b.100d vector\n",
    "    vectors = \"glove.6B.100d\", \n",
    "    unk_init = torch.Tensor.normal_)\n",
    "LABEL.build_vocab(train_data)\n",
    "BATCH_SIZE = 64\n",
    "device = torch.device('cpu')\n",
    "# Creating vocabulary iterators\n",
    "train_iterator, valid_iterator, test_iterator = data.BucketIterator.splits(\n",
    "    (train_data, valid_data, test_data),\n",
    "    sort = False, \n",
    "    batch_size = BATCH_SIZE, \n",
    "    device = device)\n",
    "# Building the training model\n",
    "class myModel(nn.Module):\n",
    "    def __init__(self, vocab_size, embedding_dim, n_filters, filter_sizes, output_dim, \n",
    "                 dropout, pad_idx):\n",
    "        super().__init__()\n",
    "        self.embedding = nn.Embedding(vocab_size, embedding_dim, padding_idx = pad_idx)\n",
    "        self.convs = nn.ModuleList([\n",
    "                                    nn.Conv2d(in_channels = 1, \n",
    "                                              out_channels = n_filters, \n",
    "                                              kernel_size = (fs, embedding_dim)) \n",
    "                                    for fs in filter_sizes\n",
    "                                    ])\n",
    "        self.fc = nn.Linear(len(filter_sizes) * n_filters, output_dim)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "    def forward(self, text):\n",
    "        embedded = self.embedding(text)\n",
    "        embedded = embedded.unsqueeze(1)\n",
    "        conved = [fn.relu(conv(embedded)).squeeze(3) for conv in self.convs]\n",
    "        pooled = [fn.max_pool1d(conv, conv.shape[2]).squeeze(2) for conv in conved]\n",
    "        cat = self.dropout(torch.cat(pooled, dim = 1))\n",
    "        return self.fc(cat)\n",
    "inputDimension = len(TEXT.vocab)\n",
    "embeddingDimension = 100\n",
    "outputDimension = 1\n",
    "padding = TEXT.vocab.stoi[TEXT.pad_token]\n",
    "filterCount = 100\n",
    "filterSize = [3,4,5]\n",
    "dropout = 0.5\n",
    "model = myModel(inputDimension, embeddingDimension, filterCount, filterSize, outputDimension, dropout, padding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Copying the pre-trained vectors to the embedding layer\n",
    "pretrained_embeddings = TEXT.vocab.vectors\n",
    "model.embedding.weight.data.copy_(pretrained_embeddings)\n",
    "# Setting the unknown and padding elements to zero since they are of no use\n",
    "unknown = TEXT.vocab.stoi[TEXT.unk_token]\n",
    "model.embedding.weight.data[unknown] = torch.zeros(embeddingDimension)\n",
    "model.embedding.weight.data[padding] = torch.zeros(embeddingDimension)\n",
    "# Counting the number of trainable parameters\n",
    "def count_parameters(model):\n",
    "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "print(f'The model has {count_parameters(model):,} trainable parameters')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    The model has 5,000,301 trainable parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import torch.optim as optim\n",
    "optimizer = optim.Adam(model.parameters())\n",
    "criterion = nn.BCEWithLogitsLoss()\n",
    "# Defining function to calculate accuracy\n",
    "def binary_accuracy(preds, y):\n",
    "    rounded_preds = torch.round(torch.sigmoid(preds))\n",
    "    correct = (rounded_preds == y).float()\n",
    "    acc = correct.sum() / len(correct)\n",
    "    return acc\n",
    "# Defining function for training\n",
    "def train(model, iterator, optimizer, criterion):\n",
    "    epoch_loss = 0\n",
    "    epoch_acc = 0\n",
    "    model.train()\n",
    "    for batch in iterator:\n",
    "        optimizer.zero_grad()\n",
    "        predictions = model(batch.c).squeeze(1)\n",
    "        loss = criterion(predictions, batch.s)\n",
    "        acc = binary_accuracy(predictions, batch.s)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        epoch_loss += loss.item()\n",
    "        epoch_acc += acc.item()\n",
    "    return epoch_loss / len(iterator), epoch_acc / len(iterator)\n",
    "# Defining function for testing\n",
    "def evaluate(model, iterator, criterion):\n",
    "    epoch_loss = 0\n",
    "    epoch_acc = 0\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for batch in iterator:\n",
    "            predictions = model(batch.c).squeeze(1)\n",
    "            loss = criterion(predictions, batch.s)\n",
    "            acc = binary_accuracy(predictions, batch.s)\n",
    "            epoch_loss += loss.item()\n",
    "            epoch_acc += acc.item()\n",
    "    return epoch_loss / len(iterator), epoch_acc / len(iterator)\n",
    "# Defining function to calculate time\n",
    "def epoch_time(start_time, end_time):\n",
    "    elapsed_time = end_time - start_time\n",
    "    elapsed_mins = int(elapsed_time / 60)\n",
    "    elapsed_secs = int(elapsed_time - (elapsed_mins * 60))\n",
    "    return elapsed_mins, elapsed_secs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training the model\n",
    "N_EPOCHS = 5\n",
    "best_valid_loss = float('inf')\n",
    "for epoch in range(N_EPOCHS):\n",
    "    start_time = time.time()\n",
    "    train_loss, train_acc = train(model, train_iterator, optimizer, criterion)\n",
    "    valid_loss, valid_acc = evaluate(model, valid_iterator, criterion)\n",
    "    end_time = time.time()\n",
    "    epoch_mins, epoch_secs = epoch_time(start_time, end_time)\n",
    "    if valid_loss < best_valid_loss:\n",
    "        best_valid_loss = valid_loss\n",
    "        torch.save(model.state_dict(), 'myModelCNN.pt')\n",
    "    print(f'Epoch: {epoch+1:02}')\n",
    "    print(f'\\tEpoch Time: {epoch_mins}m {epoch_secs}s')\n",
    "    print(f'\\tTrain Loss: {train_loss:.3f} | Train Acc: {train_acc*100:.2f}%')\n",
    "    print(f'\\t Val. Loss: {valid_loss:.3f} |  Val. Acc: {valid_acc*100:.2f}%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Epoch: 01\n",
    "\n",
    "    Epoch Time: 45m 39s\n",
    "    Train Loss: 0.480 | Train Acc: 73.42%\n",
    "    Val. Loss: 0.413 |  Val. Acc: 73.04%\n",
    "\n",
    "Epoch: 02\n",
    "\n",
    "    Epoch Time: 25m 22s\n",
    "    Train Loss: 0.465 | Train Acc: 73.78%\n",
    "    Val. Loss: 0.433 |  Val. Acc: 73.79%\n",
    "\n",
    "Epoch: 03\n",
    "\n",
    "    Epoch Time: 23m 41s\n",
    "    Train Loss: 0.449 | Train Acc: 75.45%\n",
    "    Val. Loss: 0.419 |  Val. Acc: 75.57%\n",
    "\n",
    "Epoch: 04\n",
    "\n",
    "    Epoch Time: 21m 34s\n",
    "    Train Loss: 0.418 | Train Acc: 76.31%\n",
    "    Val. Loss: 0.397 |  Val. Acc: 76.19%\n",
    "\n",
    "Epoch: 05\n",
    "\n",
    "    Epoch Time: 22m 31s\n",
    "    Train Loss: 0.378 | Train Acc: 79.90%\n",
    "    Val. Loss: 0.381 |  Val. Acc: 77.94%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Testing the model\n",
    "model.load_state_dict(torch.load('myModelCNN.pt'))\n",
    "test_loss, test_acc = evaluate(model, test_iterator, criterion)\n",
    "# Calculating test accuracy\n",
    "print(f'Test Loss: {test_loss:.3f} | Test Acc: {test_acc*100:.2f}%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    Test Loss: 0.309\n",
    "    Test Acc: 75.42%"
   ]
  }
 ]
}